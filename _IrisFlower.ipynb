{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88564c7e-a461-43a6-bc02-b60685a2cb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "Model Accuracy: 1.00\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      1.00      1.00         9\n",
      " Iris-virginica       1.00      1.00      1.00        11\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Enter the flower measurements:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sepal Length (cm):  5.1\n",
      "Sepal Width (cm):  3.4\n",
      "Petal Length (cm):  4.1\n",
      "Petal Width (cm):  .2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Iris species: Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load the Iris dataset from a CSV file.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check the first few rows to determine the actual feature columns\n",
    "    print(df.head())  \n",
    "    \n",
    "    # Assuming the dataset has an ID column, drop the first column\n",
    "    df = df.iloc[:, 1:]  # Adjust index based on dataset structure\n",
    "\n",
    "    X = df.iloc[:, :-1].values  # Feature columns (4)\n",
    "    y = df.iloc[:, -1].values   # Target column (species)\n",
    "    return X, y, np.unique(y)\n",
    "\n",
    "\n",
    "def preprocess_data(X):\n",
    "    \"\"\"Standardize the feature values.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"Train the RandomForest model.\"\"\"\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate the model's performance.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "def predict_species(model, scaler, target_names):\n",
    "    \"\"\"Allow the user to input measurements and predict the species.\"\"\"\n",
    "    print(\"\\nEnter the flower measurements:\")\n",
    "    sepal_length = float(input(\"Sepal Length (cm): \"))\n",
    "    sepal_width = float(input(\"Sepal Width (cm): \"))\n",
    "    petal_length = float(input(\"Petal Length (cm): \"))\n",
    "    petal_width = float(input(\"Petal Width (cm): \"))\n",
    "    \n",
    "    user_input = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
    "    user_input_scaled = scaler.transform(user_input)\n",
    "    prediction = model.predict(user_input_scaled)\n",
    "    print(f\"Predicted Iris species: {prediction[0]}\")\n",
    "\n",
    "def main():\n",
    "    file_path = \"C:/Users/Manasvi/OneDrive/Desktop/Iris.csv\"  # Update with actual file path\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    X, y, target_names = load_data(file_path)\n",
    "    X_scaled, scaler = preprocess_data(X)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # Save model and scaler\n",
    "    joblib.dump(model, \"iris_model.pkl\")\n",
    "    joblib.dump(scaler, \"scaler.pkl\")\n",
    "    \n",
    "    # Predict new data\n",
    "    predict_species(model, scaler, target_names)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab085d0-16bc-492d-961f-f0de1885184a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
